{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 575,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0174140182847192,
      "grad_norm": 0.38349980115890503,
      "learning_rate": 4.973913043478261e-05,
      "loss": 1.7157,
      "step": 10
    },
    {
      "epoch": 0.0348280365694384,
      "grad_norm": 0.3952949643135071,
      "learning_rate": 4.9449275362318844e-05,
      "loss": 1.5529,
      "step": 20
    },
    {
      "epoch": 0.052242054854157595,
      "grad_norm": 0.5607662796974182,
      "learning_rate": 4.915942028985507e-05,
      "loss": 1.4329,
      "step": 30
    },
    {
      "epoch": 0.0696560731388768,
      "grad_norm": 0.43949711322784424,
      "learning_rate": 4.8869565217391305e-05,
      "loss": 1.2247,
      "step": 40
    },
    {
      "epoch": 0.087070091423596,
      "grad_norm": 0.486707866191864,
      "learning_rate": 4.857971014492754e-05,
      "loss": 1.0965,
      "step": 50
    },
    {
      "epoch": 0.10448410970831519,
      "grad_norm": 0.4224332869052887,
      "learning_rate": 4.828985507246377e-05,
      "loss": 0.9744,
      "step": 60
    },
    {
      "epoch": 0.12189812799303439,
      "grad_norm": 0.41776323318481445,
      "learning_rate": 4.8e-05,
      "loss": 0.8751,
      "step": 70
    },
    {
      "epoch": 0.1393121462777536,
      "grad_norm": 0.5370748043060303,
      "learning_rate": 4.7710144927536235e-05,
      "loss": 0.8209,
      "step": 80
    },
    {
      "epoch": 0.1567261645624728,
      "grad_norm": 0.48235076665878296,
      "learning_rate": 4.742028985507246e-05,
      "loss": 0.7422,
      "step": 90
    },
    {
      "epoch": 0.174140182847192,
      "grad_norm": 0.5963638424873352,
      "learning_rate": 4.71304347826087e-05,
      "loss": 0.681,
      "step": 100
    },
    {
      "epoch": 0.19155420113191118,
      "grad_norm": 0.5983068943023682,
      "learning_rate": 4.6840579710144924e-05,
      "loss": 0.6294,
      "step": 110
    },
    {
      "epoch": 0.20896821941663038,
      "grad_norm": 0.7028219103813171,
      "learning_rate": 4.655072463768116e-05,
      "loss": 0.5867,
      "step": 120
    },
    {
      "epoch": 0.22638223770134958,
      "grad_norm": 0.7354074716567993,
      "learning_rate": 4.62608695652174e-05,
      "loss": 0.5443,
      "step": 130
    },
    {
      "epoch": 0.24379625598606877,
      "grad_norm": 0.8524731397628784,
      "learning_rate": 4.597101449275363e-05,
      "loss": 0.5246,
      "step": 140
    },
    {
      "epoch": 0.26121027427078797,
      "grad_norm": 0.651517927646637,
      "learning_rate": 4.568115942028986e-05,
      "loss": 0.5021,
      "step": 150
    },
    {
      "epoch": 0.2786242925555072,
      "grad_norm": 0.6003255248069763,
      "learning_rate": 4.539130434782609e-05,
      "loss": 0.4882,
      "step": 160
    },
    {
      "epoch": 0.29603831084022636,
      "grad_norm": 0.5999476313591003,
      "learning_rate": 4.510144927536232e-05,
      "loss": 0.4753,
      "step": 170
    },
    {
      "epoch": 0.3134523291249456,
      "grad_norm": 0.48077094554901123,
      "learning_rate": 4.481159420289856e-05,
      "loss": 0.4742,
      "step": 180
    },
    {
      "epoch": 0.3308663474096648,
      "grad_norm": 0.6054229140281677,
      "learning_rate": 4.4521739130434784e-05,
      "loss": 0.4611,
      "step": 190
    },
    {
      "epoch": 0.348280365694384,
      "grad_norm": 0.5810563564300537,
      "learning_rate": 4.423188405797102e-05,
      "loss": 0.4655,
      "step": 200
    },
    {
      "epoch": 0.3656943839791032,
      "grad_norm": 0.6583517789840698,
      "learning_rate": 4.394202898550725e-05,
      "loss": 0.4665,
      "step": 210
    },
    {
      "epoch": 0.38310840226382237,
      "grad_norm": 0.5998287796974182,
      "learning_rate": 4.365217391304348e-05,
      "loss": 0.4546,
      "step": 220
    },
    {
      "epoch": 0.4005224205485416,
      "grad_norm": 0.6505181193351746,
      "learning_rate": 4.3362318840579714e-05,
      "loss": 0.4563,
      "step": 230
    },
    {
      "epoch": 0.41793643883326076,
      "grad_norm": 0.5513738393783569,
      "learning_rate": 4.307246376811595e-05,
      "loss": 0.4517,
      "step": 240
    },
    {
      "epoch": 0.43535045711798,
      "grad_norm": 0.4507105052471161,
      "learning_rate": 4.2782608695652176e-05,
      "loss": 0.4389,
      "step": 250
    },
    {
      "epoch": 0.45276447540269915,
      "grad_norm": 0.5487565994262695,
      "learning_rate": 4.249275362318841e-05,
      "loss": 0.4406,
      "step": 260
    },
    {
      "epoch": 0.4701784936874184,
      "grad_norm": 0.47472843527793884,
      "learning_rate": 4.220289855072464e-05,
      "loss": 0.4496,
      "step": 270
    },
    {
      "epoch": 0.48759251197213754,
      "grad_norm": 0.5433244109153748,
      "learning_rate": 4.191304347826087e-05,
      "loss": 0.4392,
      "step": 280
    },
    {
      "epoch": 0.5050065302568568,
      "grad_norm": 0.6462593078613281,
      "learning_rate": 4.1623188405797105e-05,
      "loss": 0.4356,
      "step": 290
    },
    {
      "epoch": 0.5224205485415759,
      "grad_norm": 0.552653968334198,
      "learning_rate": 4.133333333333333e-05,
      "loss": 0.4357,
      "step": 300
    },
    {
      "epoch": 0.5398345668262952,
      "grad_norm": 0.5202423334121704,
      "learning_rate": 4.104347826086957e-05,
      "loss": 0.4334,
      "step": 310
    },
    {
      "epoch": 0.5572485851110144,
      "grad_norm": 0.5567255616188049,
      "learning_rate": 4.07536231884058e-05,
      "loss": 0.4287,
      "step": 320
    },
    {
      "epoch": 0.5746626033957336,
      "grad_norm": 0.5624764561653137,
      "learning_rate": 4.046376811594203e-05,
      "loss": 0.4223,
      "step": 330
    },
    {
      "epoch": 0.5920766216804527,
      "grad_norm": 0.482008695602417,
      "learning_rate": 4.017391304347826e-05,
      "loss": 0.4261,
      "step": 340
    },
    {
      "epoch": 0.6094906399651719,
      "grad_norm": 0.6114346385002136,
      "learning_rate": 3.988405797101449e-05,
      "loss": 0.428,
      "step": 350
    },
    {
      "epoch": 0.6269046582498912,
      "grad_norm": 0.5301703810691833,
      "learning_rate": 3.9594202898550724e-05,
      "loss": 0.4247,
      "step": 360
    },
    {
      "epoch": 0.6443186765346104,
      "grad_norm": 0.5463353395462036,
      "learning_rate": 3.930434782608696e-05,
      "loss": 0.4174,
      "step": 370
    },
    {
      "epoch": 0.6617326948193296,
      "grad_norm": 0.5233883261680603,
      "learning_rate": 3.9014492753623186e-05,
      "loss": 0.4162,
      "step": 380
    },
    {
      "epoch": 0.6791467131040487,
      "grad_norm": 0.6297938823699951,
      "learning_rate": 3.872463768115942e-05,
      "loss": 0.4128,
      "step": 390
    },
    {
      "epoch": 0.696560731388768,
      "grad_norm": 0.5099122524261475,
      "learning_rate": 3.8434782608695654e-05,
      "loss": 0.4181,
      "step": 400
    },
    {
      "epoch": 0.7139747496734872,
      "grad_norm": 0.49957841634750366,
      "learning_rate": 3.814492753623188e-05,
      "loss": 0.4219,
      "step": 410
    },
    {
      "epoch": 0.7313887679582064,
      "grad_norm": 0.5887097120285034,
      "learning_rate": 3.7855072463768116e-05,
      "loss": 0.4114,
      "step": 420
    },
    {
      "epoch": 0.7488027862429255,
      "grad_norm": 0.5335614681243896,
      "learning_rate": 3.756521739130435e-05,
      "loss": 0.4067,
      "step": 430
    },
    {
      "epoch": 0.7662168045276447,
      "grad_norm": 0.5631405115127563,
      "learning_rate": 3.727536231884058e-05,
      "loss": 0.415,
      "step": 440
    },
    {
      "epoch": 0.783630822812364,
      "grad_norm": 0.5567774772644043,
      "learning_rate": 3.698550724637682e-05,
      "loss": 0.4098,
      "step": 450
    },
    {
      "epoch": 0.8010448410970832,
      "grad_norm": 0.5704988837242126,
      "learning_rate": 3.6695652173913046e-05,
      "loss": 0.4109,
      "step": 460
    },
    {
      "epoch": 0.8184588593818024,
      "grad_norm": 0.5135799646377563,
      "learning_rate": 3.640579710144928e-05,
      "loss": 0.407,
      "step": 470
    },
    {
      "epoch": 0.8358728776665215,
      "grad_norm": 0.5748204588890076,
      "learning_rate": 3.6115942028985514e-05,
      "loss": 0.398,
      "step": 480
    },
    {
      "epoch": 0.8532868959512407,
      "grad_norm": 0.5462766289710999,
      "learning_rate": 3.582608695652174e-05,
      "loss": 0.3994,
      "step": 490
    },
    {
      "epoch": 0.87070091423596,
      "grad_norm": 0.5762781500816345,
      "learning_rate": 3.5536231884057976e-05,
      "loss": 0.3981,
      "step": 500
    },
    {
      "epoch": 0.8881149325206792,
      "grad_norm": 0.5547948479652405,
      "learning_rate": 3.52463768115942e-05,
      "loss": 0.4049,
      "step": 510
    },
    {
      "epoch": 0.9055289508053983,
      "grad_norm": 0.6700606346130371,
      "learning_rate": 3.495652173913044e-05,
      "loss": 0.407,
      "step": 520
    },
    {
      "epoch": 0.9229429690901175,
      "grad_norm": 0.5500355362892151,
      "learning_rate": 3.466666666666667e-05,
      "loss": 0.3962,
      "step": 530
    },
    {
      "epoch": 0.9403569873748368,
      "grad_norm": 0.5658250451087952,
      "learning_rate": 3.43768115942029e-05,
      "loss": 0.4017,
      "step": 540
    },
    {
      "epoch": 0.957771005659556,
      "grad_norm": 0.5352687239646912,
      "learning_rate": 3.408695652173913e-05,
      "loss": 0.3992,
      "step": 550
    },
    {
      "epoch": 0.9751850239442751,
      "grad_norm": 0.7195826768875122,
      "learning_rate": 3.379710144927537e-05,
      "loss": 0.3988,
      "step": 560
    },
    {
      "epoch": 0.9925990422289943,
      "grad_norm": 0.6586685180664062,
      "learning_rate": 3.3507246376811594e-05,
      "loss": 0.3941,
      "step": 570
    }
  ],
  "logging_steps": 10,
  "max_steps": 1725,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.218636181202125e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
