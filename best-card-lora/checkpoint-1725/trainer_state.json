{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 1725,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0174140182847192,
      "grad_norm": 0.38349980115890503,
      "learning_rate": 4.973913043478261e-05,
      "loss": 1.7157,
      "step": 10
    },
    {
      "epoch": 0.0348280365694384,
      "grad_norm": 0.3952949643135071,
      "learning_rate": 4.9449275362318844e-05,
      "loss": 1.5529,
      "step": 20
    },
    {
      "epoch": 0.052242054854157595,
      "grad_norm": 0.5607662796974182,
      "learning_rate": 4.915942028985507e-05,
      "loss": 1.4329,
      "step": 30
    },
    {
      "epoch": 0.0696560731388768,
      "grad_norm": 0.43949711322784424,
      "learning_rate": 4.8869565217391305e-05,
      "loss": 1.2247,
      "step": 40
    },
    {
      "epoch": 0.087070091423596,
      "grad_norm": 0.486707866191864,
      "learning_rate": 4.857971014492754e-05,
      "loss": 1.0965,
      "step": 50
    },
    {
      "epoch": 0.10448410970831519,
      "grad_norm": 0.4224332869052887,
      "learning_rate": 4.828985507246377e-05,
      "loss": 0.9744,
      "step": 60
    },
    {
      "epoch": 0.12189812799303439,
      "grad_norm": 0.41776323318481445,
      "learning_rate": 4.8e-05,
      "loss": 0.8751,
      "step": 70
    },
    {
      "epoch": 0.1393121462777536,
      "grad_norm": 0.5370748043060303,
      "learning_rate": 4.7710144927536235e-05,
      "loss": 0.8209,
      "step": 80
    },
    {
      "epoch": 0.1567261645624728,
      "grad_norm": 0.48235076665878296,
      "learning_rate": 4.742028985507246e-05,
      "loss": 0.7422,
      "step": 90
    },
    {
      "epoch": 0.174140182847192,
      "grad_norm": 0.5963638424873352,
      "learning_rate": 4.71304347826087e-05,
      "loss": 0.681,
      "step": 100
    },
    {
      "epoch": 0.19155420113191118,
      "grad_norm": 0.5983068943023682,
      "learning_rate": 4.6840579710144924e-05,
      "loss": 0.6294,
      "step": 110
    },
    {
      "epoch": 0.20896821941663038,
      "grad_norm": 0.7028219103813171,
      "learning_rate": 4.655072463768116e-05,
      "loss": 0.5867,
      "step": 120
    },
    {
      "epoch": 0.22638223770134958,
      "grad_norm": 0.7354074716567993,
      "learning_rate": 4.62608695652174e-05,
      "loss": 0.5443,
      "step": 130
    },
    {
      "epoch": 0.24379625598606877,
      "grad_norm": 0.8524731397628784,
      "learning_rate": 4.597101449275363e-05,
      "loss": 0.5246,
      "step": 140
    },
    {
      "epoch": 0.26121027427078797,
      "grad_norm": 0.651517927646637,
      "learning_rate": 4.568115942028986e-05,
      "loss": 0.5021,
      "step": 150
    },
    {
      "epoch": 0.2786242925555072,
      "grad_norm": 0.6003255248069763,
      "learning_rate": 4.539130434782609e-05,
      "loss": 0.4882,
      "step": 160
    },
    {
      "epoch": 0.29603831084022636,
      "grad_norm": 0.5999476313591003,
      "learning_rate": 4.510144927536232e-05,
      "loss": 0.4753,
      "step": 170
    },
    {
      "epoch": 0.3134523291249456,
      "grad_norm": 0.48077094554901123,
      "learning_rate": 4.481159420289856e-05,
      "loss": 0.4742,
      "step": 180
    },
    {
      "epoch": 0.3308663474096648,
      "grad_norm": 0.6054229140281677,
      "learning_rate": 4.4521739130434784e-05,
      "loss": 0.4611,
      "step": 190
    },
    {
      "epoch": 0.348280365694384,
      "grad_norm": 0.5810563564300537,
      "learning_rate": 4.423188405797102e-05,
      "loss": 0.4655,
      "step": 200
    },
    {
      "epoch": 0.3656943839791032,
      "grad_norm": 0.6583517789840698,
      "learning_rate": 4.394202898550725e-05,
      "loss": 0.4665,
      "step": 210
    },
    {
      "epoch": 0.38310840226382237,
      "grad_norm": 0.5998287796974182,
      "learning_rate": 4.365217391304348e-05,
      "loss": 0.4546,
      "step": 220
    },
    {
      "epoch": 0.4005224205485416,
      "grad_norm": 0.6505181193351746,
      "learning_rate": 4.3362318840579714e-05,
      "loss": 0.4563,
      "step": 230
    },
    {
      "epoch": 0.41793643883326076,
      "grad_norm": 0.5513738393783569,
      "learning_rate": 4.307246376811595e-05,
      "loss": 0.4517,
      "step": 240
    },
    {
      "epoch": 0.43535045711798,
      "grad_norm": 0.4507105052471161,
      "learning_rate": 4.2782608695652176e-05,
      "loss": 0.4389,
      "step": 250
    },
    {
      "epoch": 0.45276447540269915,
      "grad_norm": 0.5487565994262695,
      "learning_rate": 4.249275362318841e-05,
      "loss": 0.4406,
      "step": 260
    },
    {
      "epoch": 0.4701784936874184,
      "grad_norm": 0.47472843527793884,
      "learning_rate": 4.220289855072464e-05,
      "loss": 0.4496,
      "step": 270
    },
    {
      "epoch": 0.48759251197213754,
      "grad_norm": 0.5433244109153748,
      "learning_rate": 4.191304347826087e-05,
      "loss": 0.4392,
      "step": 280
    },
    {
      "epoch": 0.5050065302568568,
      "grad_norm": 0.6462593078613281,
      "learning_rate": 4.1623188405797105e-05,
      "loss": 0.4356,
      "step": 290
    },
    {
      "epoch": 0.5224205485415759,
      "grad_norm": 0.552653968334198,
      "learning_rate": 4.133333333333333e-05,
      "loss": 0.4357,
      "step": 300
    },
    {
      "epoch": 0.5398345668262952,
      "grad_norm": 0.5202423334121704,
      "learning_rate": 4.104347826086957e-05,
      "loss": 0.4334,
      "step": 310
    },
    {
      "epoch": 0.5572485851110144,
      "grad_norm": 0.5567255616188049,
      "learning_rate": 4.07536231884058e-05,
      "loss": 0.4287,
      "step": 320
    },
    {
      "epoch": 0.5746626033957336,
      "grad_norm": 0.5624764561653137,
      "learning_rate": 4.046376811594203e-05,
      "loss": 0.4223,
      "step": 330
    },
    {
      "epoch": 0.5920766216804527,
      "grad_norm": 0.482008695602417,
      "learning_rate": 4.017391304347826e-05,
      "loss": 0.4261,
      "step": 340
    },
    {
      "epoch": 0.6094906399651719,
      "grad_norm": 0.6114346385002136,
      "learning_rate": 3.988405797101449e-05,
      "loss": 0.428,
      "step": 350
    },
    {
      "epoch": 0.6269046582498912,
      "grad_norm": 0.5301703810691833,
      "learning_rate": 3.9594202898550724e-05,
      "loss": 0.4247,
      "step": 360
    },
    {
      "epoch": 0.6443186765346104,
      "grad_norm": 0.5463353395462036,
      "learning_rate": 3.930434782608696e-05,
      "loss": 0.4174,
      "step": 370
    },
    {
      "epoch": 0.6617326948193296,
      "grad_norm": 0.5233883261680603,
      "learning_rate": 3.9014492753623186e-05,
      "loss": 0.4162,
      "step": 380
    },
    {
      "epoch": 0.6791467131040487,
      "grad_norm": 0.6297938823699951,
      "learning_rate": 3.872463768115942e-05,
      "loss": 0.4128,
      "step": 390
    },
    {
      "epoch": 0.696560731388768,
      "grad_norm": 0.5099122524261475,
      "learning_rate": 3.8434782608695654e-05,
      "loss": 0.4181,
      "step": 400
    },
    {
      "epoch": 0.7139747496734872,
      "grad_norm": 0.49957841634750366,
      "learning_rate": 3.814492753623188e-05,
      "loss": 0.4219,
      "step": 410
    },
    {
      "epoch": 0.7313887679582064,
      "grad_norm": 0.5887097120285034,
      "learning_rate": 3.7855072463768116e-05,
      "loss": 0.4114,
      "step": 420
    },
    {
      "epoch": 0.7488027862429255,
      "grad_norm": 0.5335614681243896,
      "learning_rate": 3.756521739130435e-05,
      "loss": 0.4067,
      "step": 430
    },
    {
      "epoch": 0.7662168045276447,
      "grad_norm": 0.5631405115127563,
      "learning_rate": 3.727536231884058e-05,
      "loss": 0.415,
      "step": 440
    },
    {
      "epoch": 0.783630822812364,
      "grad_norm": 0.5567774772644043,
      "learning_rate": 3.698550724637682e-05,
      "loss": 0.4098,
      "step": 450
    },
    {
      "epoch": 0.8010448410970832,
      "grad_norm": 0.5704988837242126,
      "learning_rate": 3.6695652173913046e-05,
      "loss": 0.4109,
      "step": 460
    },
    {
      "epoch": 0.8184588593818024,
      "grad_norm": 0.5135799646377563,
      "learning_rate": 3.640579710144928e-05,
      "loss": 0.407,
      "step": 470
    },
    {
      "epoch": 0.8358728776665215,
      "grad_norm": 0.5748204588890076,
      "learning_rate": 3.6115942028985514e-05,
      "loss": 0.398,
      "step": 480
    },
    {
      "epoch": 0.8532868959512407,
      "grad_norm": 0.5462766289710999,
      "learning_rate": 3.582608695652174e-05,
      "loss": 0.3994,
      "step": 490
    },
    {
      "epoch": 0.87070091423596,
      "grad_norm": 0.5762781500816345,
      "learning_rate": 3.5536231884057976e-05,
      "loss": 0.3981,
      "step": 500
    },
    {
      "epoch": 0.8881149325206792,
      "grad_norm": 0.5547948479652405,
      "learning_rate": 3.52463768115942e-05,
      "loss": 0.4049,
      "step": 510
    },
    {
      "epoch": 0.9055289508053983,
      "grad_norm": 0.6700606346130371,
      "learning_rate": 3.495652173913044e-05,
      "loss": 0.407,
      "step": 520
    },
    {
      "epoch": 0.9229429690901175,
      "grad_norm": 0.5500355362892151,
      "learning_rate": 3.466666666666667e-05,
      "loss": 0.3962,
      "step": 530
    },
    {
      "epoch": 0.9403569873748368,
      "grad_norm": 0.5658250451087952,
      "learning_rate": 3.43768115942029e-05,
      "loss": 0.4017,
      "step": 540
    },
    {
      "epoch": 0.957771005659556,
      "grad_norm": 0.5352687239646912,
      "learning_rate": 3.408695652173913e-05,
      "loss": 0.3992,
      "step": 550
    },
    {
      "epoch": 0.9751850239442751,
      "grad_norm": 0.7195826768875122,
      "learning_rate": 3.379710144927537e-05,
      "loss": 0.3988,
      "step": 560
    },
    {
      "epoch": 0.9925990422289943,
      "grad_norm": 0.6586685180664062,
      "learning_rate": 3.3507246376811594e-05,
      "loss": 0.3941,
      "step": 570
    },
    {
      "epoch": 1.0087070091423596,
      "grad_norm": 0.6531350612640381,
      "learning_rate": 3.321739130434783e-05,
      "loss": 0.3992,
      "step": 580
    },
    {
      "epoch": 1.026121027427079,
      "grad_norm": 0.6106867790222168,
      "learning_rate": 3.292753623188406e-05,
      "loss": 0.3955,
      "step": 590
    },
    {
      "epoch": 1.043535045711798,
      "grad_norm": 0.5671757459640503,
      "learning_rate": 3.263768115942029e-05,
      "loss": 0.3982,
      "step": 600
    },
    {
      "epoch": 1.0609490639965171,
      "grad_norm": 0.7358482480049133,
      "learning_rate": 3.2347826086956524e-05,
      "loss": 0.3949,
      "step": 610
    },
    {
      "epoch": 1.0783630822812365,
      "grad_norm": 0.8557384610176086,
      "learning_rate": 3.205797101449275e-05,
      "loss": 0.3914,
      "step": 620
    },
    {
      "epoch": 1.0957771005659556,
      "grad_norm": 0.5128669142723083,
      "learning_rate": 3.1768115942028986e-05,
      "loss": 0.3938,
      "step": 630
    },
    {
      "epoch": 1.1131911188506747,
      "grad_norm": 0.6750893592834473,
      "learning_rate": 3.147826086956522e-05,
      "loss": 0.3869,
      "step": 640
    },
    {
      "epoch": 1.130605137135394,
      "grad_norm": 0.5940831303596497,
      "learning_rate": 3.118840579710145e-05,
      "loss": 0.3873,
      "step": 650
    },
    {
      "epoch": 1.1480191554201131,
      "grad_norm": 0.7279660105705261,
      "learning_rate": 3.089855072463768e-05,
      "loss": 0.3917,
      "step": 660
    },
    {
      "epoch": 1.1654331737048325,
      "grad_norm": 0.587378740310669,
      "learning_rate": 3.0608695652173916e-05,
      "loss": 0.3866,
      "step": 670
    },
    {
      "epoch": 1.1828471919895516,
      "grad_norm": 0.6552067995071411,
      "learning_rate": 3.0318840579710147e-05,
      "loss": 0.3929,
      "step": 680
    },
    {
      "epoch": 1.2002612102742707,
      "grad_norm": 0.5710884928703308,
      "learning_rate": 3.0028985507246377e-05,
      "loss": 0.3898,
      "step": 690
    },
    {
      "epoch": 1.21767522855899,
      "grad_norm": 0.5398155450820923,
      "learning_rate": 2.9739130434782608e-05,
      "loss": 0.3885,
      "step": 700
    },
    {
      "epoch": 1.2350892468437091,
      "grad_norm": 0.6374555826187134,
      "learning_rate": 2.944927536231884e-05,
      "loss": 0.3814,
      "step": 710
    },
    {
      "epoch": 1.2525032651284285,
      "grad_norm": 0.5508706569671631,
      "learning_rate": 2.9159420289855073e-05,
      "loss": 0.3853,
      "step": 720
    },
    {
      "epoch": 1.2699172834131476,
      "grad_norm": 0.6236058473587036,
      "learning_rate": 2.8869565217391304e-05,
      "loss": 0.3892,
      "step": 730
    },
    {
      "epoch": 1.2873313016978667,
      "grad_norm": 0.6059921979904175,
      "learning_rate": 2.8579710144927535e-05,
      "loss": 0.3753,
      "step": 740
    },
    {
      "epoch": 1.304745319982586,
      "grad_norm": 0.5654540657997131,
      "learning_rate": 2.8289855072463765e-05,
      "loss": 0.3846,
      "step": 750
    },
    {
      "epoch": 1.3221593382673051,
      "grad_norm": 0.6587924361228943,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 0.3865,
      "step": 760
    },
    {
      "epoch": 1.3395733565520245,
      "grad_norm": 0.7363871932029724,
      "learning_rate": 2.7710144927536237e-05,
      "loss": 0.3887,
      "step": 770
    },
    {
      "epoch": 1.3569873748367436,
      "grad_norm": 0.7082313895225525,
      "learning_rate": 2.7420289855072468e-05,
      "loss": 0.3823,
      "step": 780
    },
    {
      "epoch": 1.3744013931214627,
      "grad_norm": 0.7923842668533325,
      "learning_rate": 2.71304347826087e-05,
      "loss": 0.3755,
      "step": 790
    },
    {
      "epoch": 1.391815411406182,
      "grad_norm": 0.5647444725036621,
      "learning_rate": 2.684057971014493e-05,
      "loss": 0.3762,
      "step": 800
    },
    {
      "epoch": 1.4092294296909011,
      "grad_norm": 0.7747671008110046,
      "learning_rate": 2.6550724637681164e-05,
      "loss": 0.3788,
      "step": 810
    },
    {
      "epoch": 1.4266434479756205,
      "grad_norm": 0.6134039759635925,
      "learning_rate": 2.6260869565217394e-05,
      "loss": 0.3812,
      "step": 820
    },
    {
      "epoch": 1.4440574662603396,
      "grad_norm": 0.663334846496582,
      "learning_rate": 2.5971014492753625e-05,
      "loss": 0.381,
      "step": 830
    },
    {
      "epoch": 1.4614714845450587,
      "grad_norm": 0.6302284598350525,
      "learning_rate": 2.5681159420289856e-05,
      "loss": 0.379,
      "step": 840
    },
    {
      "epoch": 1.478885502829778,
      "grad_norm": 0.7499869465827942,
      "learning_rate": 2.539130434782609e-05,
      "loss": 0.3791,
      "step": 850
    },
    {
      "epoch": 1.4962995211144972,
      "grad_norm": 0.6180691123008728,
      "learning_rate": 2.510144927536232e-05,
      "loss": 0.3806,
      "step": 860
    },
    {
      "epoch": 1.5137135393992165,
      "grad_norm": 0.6118239760398865,
      "learning_rate": 2.4811594202898552e-05,
      "loss": 0.3782,
      "step": 870
    },
    {
      "epoch": 1.5311275576839356,
      "grad_norm": 0.7716754674911499,
      "learning_rate": 2.4521739130434786e-05,
      "loss": 0.3852,
      "step": 880
    },
    {
      "epoch": 1.5485415759686547,
      "grad_norm": 0.7413915395736694,
      "learning_rate": 2.4231884057971017e-05,
      "loss": 0.3781,
      "step": 890
    },
    {
      "epoch": 1.5659555942533738,
      "grad_norm": 0.7021240592002869,
      "learning_rate": 2.3942028985507247e-05,
      "loss": 0.3775,
      "step": 900
    },
    {
      "epoch": 1.5833696125380932,
      "grad_norm": 0.7184624075889587,
      "learning_rate": 2.3652173913043478e-05,
      "loss": 0.3697,
      "step": 910
    },
    {
      "epoch": 1.6007836308228125,
      "grad_norm": 0.6837760210037231,
      "learning_rate": 2.3362318840579712e-05,
      "loss": 0.373,
      "step": 920
    },
    {
      "epoch": 1.6181976491075316,
      "grad_norm": 0.7083990573883057,
      "learning_rate": 2.3072463768115943e-05,
      "loss": 0.3753,
      "step": 930
    },
    {
      "epoch": 1.6356116673922507,
      "grad_norm": 0.6800537705421448,
      "learning_rate": 2.2782608695652174e-05,
      "loss": 0.3771,
      "step": 940
    },
    {
      "epoch": 1.6530256856769698,
      "grad_norm": 0.7364333271980286,
      "learning_rate": 2.2492753623188405e-05,
      "loss": 0.3695,
      "step": 950
    },
    {
      "epoch": 1.6704397039616892,
      "grad_norm": 0.7482955455780029,
      "learning_rate": 2.220289855072464e-05,
      "loss": 0.3745,
      "step": 960
    },
    {
      "epoch": 1.6878537222464085,
      "grad_norm": 0.8340284824371338,
      "learning_rate": 2.191304347826087e-05,
      "loss": 0.3774,
      "step": 970
    },
    {
      "epoch": 1.7052677405311276,
      "grad_norm": 0.9133102893829346,
      "learning_rate": 2.16231884057971e-05,
      "loss": 0.3683,
      "step": 980
    },
    {
      "epoch": 1.7226817588158467,
      "grad_norm": 0.7125125527381897,
      "learning_rate": 2.1333333333333335e-05,
      "loss": 0.3693,
      "step": 990
    },
    {
      "epoch": 1.7400957771005658,
      "grad_norm": 0.7148836851119995,
      "learning_rate": 2.104347826086957e-05,
      "loss": 0.3697,
      "step": 1000
    },
    {
      "epoch": 1.7575097953852852,
      "grad_norm": 0.779942512512207,
      "learning_rate": 2.07536231884058e-05,
      "loss": 0.3665,
      "step": 1010
    },
    {
      "epoch": 1.7749238136700045,
      "grad_norm": 0.8851848244667053,
      "learning_rate": 2.046376811594203e-05,
      "loss": 0.3705,
      "step": 1020
    },
    {
      "epoch": 1.7923378319547236,
      "grad_norm": 0.6632656455039978,
      "learning_rate": 2.017391304347826e-05,
      "loss": 0.3674,
      "step": 1030
    },
    {
      "epoch": 1.8097518502394427,
      "grad_norm": 0.8226737976074219,
      "learning_rate": 1.9884057971014495e-05,
      "loss": 0.3708,
      "step": 1040
    },
    {
      "epoch": 1.8271658685241619,
      "grad_norm": 0.7798696160316467,
      "learning_rate": 1.9594202898550726e-05,
      "loss": 0.3721,
      "step": 1050
    },
    {
      "epoch": 1.8445798868088812,
      "grad_norm": 0.7617632150650024,
      "learning_rate": 1.9304347826086957e-05,
      "loss": 0.3668,
      "step": 1060
    },
    {
      "epoch": 1.8619939050936003,
      "grad_norm": 0.7833043336868286,
      "learning_rate": 1.9014492753623188e-05,
      "loss": 0.3699,
      "step": 1070
    },
    {
      "epoch": 1.8794079233783196,
      "grad_norm": 0.959794819355011,
      "learning_rate": 1.8724637681159422e-05,
      "loss": 0.3661,
      "step": 1080
    },
    {
      "epoch": 1.8968219416630387,
      "grad_norm": 0.7777268290519714,
      "learning_rate": 1.8434782608695653e-05,
      "loss": 0.3711,
      "step": 1090
    },
    {
      "epoch": 1.9142359599477579,
      "grad_norm": 0.6541284322738647,
      "learning_rate": 1.8144927536231883e-05,
      "loss": 0.3738,
      "step": 1100
    },
    {
      "epoch": 1.9316499782324772,
      "grad_norm": 0.7317189574241638,
      "learning_rate": 1.7855072463768118e-05,
      "loss": 0.36,
      "step": 1110
    },
    {
      "epoch": 1.9490639965171963,
      "grad_norm": 0.9756919741630554,
      "learning_rate": 1.756521739130435e-05,
      "loss": 0.3722,
      "step": 1120
    },
    {
      "epoch": 1.9664780148019156,
      "grad_norm": 0.6872373223304749,
      "learning_rate": 1.727536231884058e-05,
      "loss": 0.3664,
      "step": 1130
    },
    {
      "epoch": 1.9838920330866348,
      "grad_norm": 0.7630048990249634,
      "learning_rate": 1.698550724637681e-05,
      "loss": 0.3592,
      "step": 1140
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.3584705591201782,
      "learning_rate": 1.6695652173913044e-05,
      "loss": 0.3528,
      "step": 1150
    },
    {
      "epoch": 2.017414018284719,
      "grad_norm": 0.9004232883453369,
      "learning_rate": 1.6405797101449278e-05,
      "loss": 0.361,
      "step": 1160
    },
    {
      "epoch": 2.0348280365694382,
      "grad_norm": 0.7002597451210022,
      "learning_rate": 1.611594202898551e-05,
      "loss": 0.3609,
      "step": 1170
    },
    {
      "epoch": 2.052242054854158,
      "grad_norm": 0.8000275492668152,
      "learning_rate": 1.582608695652174e-05,
      "loss": 0.3659,
      "step": 1180
    },
    {
      "epoch": 2.069656073138877,
      "grad_norm": 0.6716435551643372,
      "learning_rate": 1.5536231884057974e-05,
      "loss": 0.3605,
      "step": 1190
    },
    {
      "epoch": 2.087070091423596,
      "grad_norm": 0.7986136674880981,
      "learning_rate": 1.5246376811594205e-05,
      "loss": 0.357,
      "step": 1200
    },
    {
      "epoch": 2.104484109708315,
      "grad_norm": 0.8098747134208679,
      "learning_rate": 1.4956521739130436e-05,
      "loss": 0.362,
      "step": 1210
    },
    {
      "epoch": 2.1218981279930342,
      "grad_norm": 0.7937766909599304,
      "learning_rate": 1.4666666666666668e-05,
      "loss": 0.3636,
      "step": 1220
    },
    {
      "epoch": 2.139312146277754,
      "grad_norm": 0.8757011890411377,
      "learning_rate": 1.4376811594202899e-05,
      "loss": 0.3547,
      "step": 1230
    },
    {
      "epoch": 2.156726164562473,
      "grad_norm": 0.7841008901596069,
      "learning_rate": 1.4086956521739131e-05,
      "loss": 0.3658,
      "step": 1240
    },
    {
      "epoch": 2.174140182847192,
      "grad_norm": 1.080187439918518,
      "learning_rate": 1.3797101449275362e-05,
      "loss": 0.3606,
      "step": 1250
    },
    {
      "epoch": 2.191554201131911,
      "grad_norm": 0.7985039353370667,
      "learning_rate": 1.3507246376811594e-05,
      "loss": 0.3597,
      "step": 1260
    },
    {
      "epoch": 2.2089682194166302,
      "grad_norm": 0.9656577110290527,
      "learning_rate": 1.3217391304347825e-05,
      "loss": 0.3601,
      "step": 1270
    },
    {
      "epoch": 2.2263822377013494,
      "grad_norm": 0.7721002697944641,
      "learning_rate": 1.2927536231884058e-05,
      "loss": 0.3632,
      "step": 1280
    },
    {
      "epoch": 2.243796255986069,
      "grad_norm": 0.8390026688575745,
      "learning_rate": 1.2637681159420289e-05,
      "loss": 0.3554,
      "step": 1290
    },
    {
      "epoch": 2.261210274270788,
      "grad_norm": 0.7950224280357361,
      "learning_rate": 1.2347826086956523e-05,
      "loss": 0.3592,
      "step": 1300
    },
    {
      "epoch": 2.278624292555507,
      "grad_norm": 0.963923990726471,
      "learning_rate": 1.2057971014492753e-05,
      "loss": 0.3592,
      "step": 1310
    },
    {
      "epoch": 2.2960383108402262,
      "grad_norm": 0.7430883646011353,
      "learning_rate": 1.1768115942028986e-05,
      "loss": 0.3603,
      "step": 1320
    },
    {
      "epoch": 2.313452329124946,
      "grad_norm": 0.8681700229644775,
      "learning_rate": 1.1478260869565217e-05,
      "loss": 0.3601,
      "step": 1330
    },
    {
      "epoch": 2.330866347409665,
      "grad_norm": 0.9278324246406555,
      "learning_rate": 1.118840579710145e-05,
      "loss": 0.3544,
      "step": 1340
    },
    {
      "epoch": 2.348280365694384,
      "grad_norm": 0.7157666683197021,
      "learning_rate": 1.0898550724637682e-05,
      "loss": 0.3583,
      "step": 1350
    },
    {
      "epoch": 2.365694383979103,
      "grad_norm": 0.7313969731330872,
      "learning_rate": 1.0608695652173914e-05,
      "loss": 0.3525,
      "step": 1360
    },
    {
      "epoch": 2.3831084022638223,
      "grad_norm": 0.8976778388023376,
      "learning_rate": 1.0318840579710145e-05,
      "loss": 0.3486,
      "step": 1370
    },
    {
      "epoch": 2.4005224205485414,
      "grad_norm": 0.8552929162979126,
      "learning_rate": 1.0028985507246377e-05,
      "loss": 0.3517,
      "step": 1380
    },
    {
      "epoch": 2.417936438833261,
      "grad_norm": 0.7146450877189636,
      "learning_rate": 9.739130434782608e-06,
      "loss": 0.3542,
      "step": 1390
    },
    {
      "epoch": 2.43535045711798,
      "grad_norm": 0.7928034663200378,
      "learning_rate": 9.44927536231884e-06,
      "loss": 0.3558,
      "step": 1400
    },
    {
      "epoch": 2.452764475402699,
      "grad_norm": 0.7889518141746521,
      "learning_rate": 9.159420289855073e-06,
      "loss": 0.3478,
      "step": 1410
    },
    {
      "epoch": 2.4701784936874183,
      "grad_norm": 0.9198840260505676,
      "learning_rate": 8.869565217391304e-06,
      "loss": 0.3551,
      "step": 1420
    },
    {
      "epoch": 2.4875925119721374,
      "grad_norm": 0.8891562819480896,
      "learning_rate": 8.579710144927536e-06,
      "loss": 0.362,
      "step": 1430
    },
    {
      "epoch": 2.505006530256857,
      "grad_norm": 0.8216522932052612,
      "learning_rate": 8.289855072463769e-06,
      "loss": 0.3563,
      "step": 1440
    },
    {
      "epoch": 2.522420548541576,
      "grad_norm": 0.9170342683792114,
      "learning_rate": 8.000000000000001e-06,
      "loss": 0.349,
      "step": 1450
    },
    {
      "epoch": 2.539834566826295,
      "grad_norm": 0.820765495300293,
      "learning_rate": 7.710144927536232e-06,
      "loss": 0.3573,
      "step": 1460
    },
    {
      "epoch": 2.5572485851110143,
      "grad_norm": 0.9802603721618652,
      "learning_rate": 7.420289855072464e-06,
      "loss": 0.3582,
      "step": 1470
    },
    {
      "epoch": 2.5746626033957334,
      "grad_norm": 1.0929489135742188,
      "learning_rate": 7.130434782608695e-06,
      "loss": 0.3505,
      "step": 1480
    },
    {
      "epoch": 2.5920766216804525,
      "grad_norm": 0.9234568476676941,
      "learning_rate": 6.840579710144927e-06,
      "loss": 0.3483,
      "step": 1490
    },
    {
      "epoch": 2.609490639965172,
      "grad_norm": 0.9363932609558105,
      "learning_rate": 6.55072463768116e-06,
      "loss": 0.3479,
      "step": 1500
    },
    {
      "epoch": 2.626904658249891,
      "grad_norm": 0.9330481886863708,
      "learning_rate": 6.260869565217392e-06,
      "loss": 0.3508,
      "step": 1510
    },
    {
      "epoch": 2.6443186765346103,
      "grad_norm": 0.8942614793777466,
      "learning_rate": 5.9710144927536236e-06,
      "loss": 0.3496,
      "step": 1520
    },
    {
      "epoch": 2.66173269481933,
      "grad_norm": 0.8468745946884155,
      "learning_rate": 5.681159420289855e-06,
      "loss": 0.344,
      "step": 1530
    },
    {
      "epoch": 2.679146713104049,
      "grad_norm": 0.7767536640167236,
      "learning_rate": 5.391304347826087e-06,
      "loss": 0.3467,
      "step": 1540
    },
    {
      "epoch": 2.696560731388768,
      "grad_norm": 0.8952184915542603,
      "learning_rate": 5.1014492753623185e-06,
      "loss": 0.348,
      "step": 1550
    },
    {
      "epoch": 2.713974749673487,
      "grad_norm": 0.792457103729248,
      "learning_rate": 4.811594202898551e-06,
      "loss": 0.3517,
      "step": 1560
    },
    {
      "epoch": 2.7313887679582063,
      "grad_norm": 0.8130372166633606,
      "learning_rate": 4.5217391304347826e-06,
      "loss": 0.3492,
      "step": 1570
    },
    {
      "epoch": 2.7488027862429254,
      "grad_norm": 0.826770007610321,
      "learning_rate": 4.231884057971015e-06,
      "loss": 0.3539,
      "step": 1580
    },
    {
      "epoch": 2.7662168045276445,
      "grad_norm": 0.7001676559448242,
      "learning_rate": 3.942028985507247e-06,
      "loss": 0.3536,
      "step": 1590
    },
    {
      "epoch": 2.783630822812364,
      "grad_norm": 0.7805948853492737,
      "learning_rate": 3.6521739130434787e-06,
      "loss": 0.3487,
      "step": 1600
    },
    {
      "epoch": 2.801044841097083,
      "grad_norm": 1.0723191499710083,
      "learning_rate": 3.3623188405797103e-06,
      "loss": 0.35,
      "step": 1610
    },
    {
      "epoch": 2.8184588593818023,
      "grad_norm": 0.8470776081085205,
      "learning_rate": 3.072463768115942e-06,
      "loss": 0.3582,
      "step": 1620
    },
    {
      "epoch": 2.8358728776665214,
      "grad_norm": 0.7662975192070007,
      "learning_rate": 2.782608695652174e-06,
      "loss": 0.3489,
      "step": 1630
    },
    {
      "epoch": 2.853286895951241,
      "grad_norm": 0.7648136615753174,
      "learning_rate": 2.4927536231884056e-06,
      "loss": 0.3496,
      "step": 1640
    },
    {
      "epoch": 2.87070091423596,
      "grad_norm": 1.0158401727676392,
      "learning_rate": 2.2028985507246377e-06,
      "loss": 0.3456,
      "step": 1650
    },
    {
      "epoch": 2.888114932520679,
      "grad_norm": 0.8668311238288879,
      "learning_rate": 1.9130434782608697e-06,
      "loss": 0.3456,
      "step": 1660
    },
    {
      "epoch": 2.9055289508053983,
      "grad_norm": 0.8139011263847351,
      "learning_rate": 1.6231884057971016e-06,
      "loss": 0.3477,
      "step": 1670
    },
    {
      "epoch": 2.9229429690901174,
      "grad_norm": 0.9542030096054077,
      "learning_rate": 1.3333333333333334e-06,
      "loss": 0.3485,
      "step": 1680
    },
    {
      "epoch": 2.9403569873748365,
      "grad_norm": 0.7576807141304016,
      "learning_rate": 1.0434782608695653e-06,
      "loss": 0.3524,
      "step": 1690
    },
    {
      "epoch": 2.957771005659556,
      "grad_norm": 0.8904616236686707,
      "learning_rate": 7.536231884057971e-07,
      "loss": 0.3523,
      "step": 1700
    },
    {
      "epoch": 2.975185023944275,
      "grad_norm": 0.8569648861885071,
      "learning_rate": 4.63768115942029e-07,
      "loss": 0.3481,
      "step": 1710
    },
    {
      "epoch": 2.9925990422289943,
      "grad_norm": 1.0053876638412476,
      "learning_rate": 1.7391304347826088e-07,
      "loss": 0.3418,
      "step": 1720
    }
  ],
  "logging_steps": 10,
  "max_steps": 1725,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 6.648906983932723e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
